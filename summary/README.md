## ReadMe for DL4NLP Summary

> Goldberg: _Neural Network Methods for Natural Language Processing_

### How to use this repository?

The repository contains:

- summary.md (main file with all content written in Markdown)

- summary.html (html file created from Markdown)

- summary.pdf (pdf file created from html file) => **best presentation** apart from Markdown itself.

### Content

- [Chapter 1: Intro](summary.md#chapter-1-intro)

- [Chapter 2: Machine Learning Pipeline](summary.md#chapter-2-machine-learning-pipeline)

- [Chapter 3: Learning Basics and Linear Models](summary.md#chapter-3-learning-basics-and-linear-models)

  - Train, Validation and Test Set
  - Linear Models
  - Linear Separability
  - Loss Functions
  - Regularization
  - Gradient-based Optimization

- [Chapter 4: Neural Networks](summary.md#chapter-4-neural-networks)

  - Activation Functions
  - Different Types of NN-Models
  - Training NNs

- [Representations (Chapters 6,8,9)](summary.md#representations-chapters-689)

  - Types of Features
  - Sparse Vector Representations
  - Encoding Categorical Features
  - Combining Dense Vectors

- [Embeddings (Chapters 10,11)](summary.md#embeddings-chapters-1011)

  - Tips & Tricks regarding Embeddings
  - Pre-Trained Word Embeddings
    - word2vec, an example of a distributed representation algorithm
  - Char-based and Sub-Word Embeddings

- [Convolutional Neural Networks (CNNs/ConvNets) (Chapter 13)](summary.md#convolutional-neural-networks-cnnsconvnets-chapter-13)

  - CNN Architecture
  - 1D Convolution over Text
  - Pooling
  - Alternative: Feature-Hashing
  - Hierarchical Convolutions
  - Issues with Deep CNNs

- [Recurrent Neural Networks (RNNs) (Chapters 14,15,16)](summary.md#recurrent-neural-networks-rnns-chapters-141516)

  - The RNN Abstraction
  - RNN Training
  - Bi-Directional RNN
  - Multi-Layer (Stacked) RNNs / _deep RNNs_
  - RNN Applications / Usages

---

Moritz Eck
